{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = 64  # Image size for resizing (64x64 pixels)\n",
    "DATA_DIR = \"./archive/simpsons_dataset\"  # Path to the dataset directory\n",
    "MAX_IMAGES_PER_CLASS = 500  # Limit images per class to manage memory\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20\n",
    "INITIAL_LR = 0.001  # Initial learning rate\n",
    "LR_STEP_SIZE = 5  # Reduce learning rate every 5 epochs\n",
    "LR_GAMMA = 0.1  # Multiply learning rate by 0.5\n",
    "VALID_EXTENSIONS = {'.jpg', '.jpeg', '.png'}  # Valid image file extensions\n",
    "\n",
    "# 1. Define data augmentation and preprocessing\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Resize to 64x64\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # 50% chance of horizontal flip\n",
    "    transforms.RandomRotation(degrees=15),  # Random rotation up to 15 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Color adjustments\n",
    "    transforms.ToTensor(),  # Convert to tensor and reorder to [C, H, W]\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# 2. Custom Dataset class to handle images and labels with augmentation\n",
    "class SimpsonsDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images  # Numpy array of images\n",
    "        self.labels = labels  # Numpy array of labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# 3. Load and preprocess the data\n",
    "# Get all character folders in the dataset directory\n",
    "label_names = sorted([name for name in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, name))])\n",
    "label_map = {name: idx for idx, name in enumerate(label_names)}\n",
    "\n",
    "# Restrict to top 10 characters with the highest number of images\n",
    "image_counts = {label: len([f for f in os.listdir(os.path.join(DATA_DIR, label))\n",
    "                           if os.path.splitext(f)[1].lower() in VALID_EXTENSIONS]) for label in label_names}\n",
    "top_characters = [c for c, _ in Counter(image_counts).most_common(10)]\n",
    "\n",
    "# Estimate total images to pre-allocate array\n",
    "total_images = sum(min(image_counts[label], MAX_IMAGES_PER_CLASS) for label in top_characters)\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load images\n",
    "for label in top_characters:\n",
    "    folder_path = os.path.join(DATA_DIR, label)\n",
    "    img_count = 0\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        if img_count >= MAX_IMAGES_PER_CLASS:\n",
    "            break\n",
    "        # Check if file has a valid image extension\n",
    "        if os.path.splitext(img_name)[1].lower() not in VALID_EXTENSIONS:\n",
    "            print(f\"Warning: Skipping non-image file {os.path.join(folder_path, img_name)}\")\n",
    "            continue\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Force RGB loading\n",
    "        if img is None:\n",
    "            print(f\"Warning: Failed to load image {img_path}\")\n",
    "            continue\n",
    "        # Convert BGR to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Resize image\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        # Verify image shape\n",
    "        if img.shape != (IMG_SIZE, IMG_SIZE, 3):\n",
    "            print(f\"Warning: Image {img_path} has invalid shape {img.shape}, expected ({IMG_SIZE}, {IMG_SIZE}, 3)\")\n",
    "            continue\n",
    "        images.append(img)\n",
    "        labels.append(label_map[label])\n",
    "        img_count += 1\n",
    "\n",
    "# Convert to numpy arrays\n",
    "try:\n",
    "    images = np.array(images, dtype=np.uint8)  # Keep as uint8 for PIL compatibility\n",
    "    labels = np.array(labels, dtype=np.int64)\n",
    "except ValueError as e:\n",
    "    print(f\"Error converting to NumPy array: {e}\")\n",
    "    print(\"Shapes of first few images:\")\n",
    "    for i, img in enumerate(images[:5]):\n",
    "        print(f\"Image {i}: shape {np.array(img).shape}\")\n",
    "    print(\"Total images collected:\", len(images))\n",
    "    raise\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets with appropriate transforms\n",
    "train_dataset = SimpsonsDataset(X_train, y_train, transform=train_transforms)\n",
    "test_dataset = SimpsonsDataset(X_test, y_test, transform=test_transforms)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Loaded {len(images)} images across {len(top_characters)} characters\")\n",
    "print(f\"Training set: {len(X_train)} images, Test set: {len(X_test)} images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
