{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# SIMPSONS CHARACTER CLASSIFICATION - CNN IMPLEMENTATION\n",
    "# =============================================================================\n",
    "\n",
    "# Diese Environment-Variablen sind super wichtig für CUDA Debugging!\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # Macht CUDA Fehler synchron - sehr nützlich für Debugging\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"    # Aktiviert Device-Side Assertions für bessere Fehlermeldungen\n",
    "\n",
    "# Standard ML/DL Libraries importieren\n",
    "import torch                              # PyTorch Core Library\n",
    "import torch.nn as nn                     # Neural Network Module für Layer-Definitionen\n",
    "import torch.nn.functional as F           # Functional API für Activation Functions etc.\n",
    "import torch.optim as optim               # Optimizer Klassen (Adam, SGD, etc.)\n",
    "from torch.utils.data import DataLoader, Dataset  # Data Loading Utilities\n",
    "import numpy as np                        # Numerical Operations\n",
    "import cv2                               # OpenCV für Image Processing\n",
    "from sklearn.model_selection import train_test_split  # Train/Test Split\n",
    "from collections import Counter          # Zum Zählen von Elementen\n",
    "from torchvision import transforms       # Image Transformations für Data Augmentation\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - Hier können wir später mit Hyperparameter Tuning experimentieren\n",
    "# =============================================================================\n",
    "IMG_SIZE = 64                           # Bildgröße - 64x64 ist gut für schnelles Training\n",
    "DATA_DIR = \"./archive/simpsons_dataset\" # Pfad zum Dataset\n",
    "MAX_IMAGES_PER_CLASS = 500              # Limitiert Bilder pro Klasse (Memory Management)\n",
    "BATCH_SIZE = 8                         # Kleine Batch Size für Memory-constrained Environments\n",
    "NUM_EPOCHS = 20                         # Anzahl Training Epochen\n",
    "INITIAL_LR = 0.001                      # Learning Rate - könnte adaptiv gemacht werden\n",
    "VALID_EXTENSIONS = {'.jpg', '.jpeg', '.png'}  # Gültige Bildformate\n",
    "\n",
    "\"\"\"\n",
    "OPTIMIERUNGSPOTENTIAL #1: CONFIGURATION\n",
    "- Config in separate YAML/JSON Datei auslagern\n",
    "- Hyperparameter Tuning mit Optuna implementieren\n",
    "- Adaptive Learning Rate Scheduling hinzufügen\n",
    "- Early Stopping basierend auf Validation Loss\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# DATA AUGMENTATION & PREPROCESSING PIPELINES\n",
    "# =============================================================================\n",
    "\n",
    "# Training Transformations - Data Augmentation verhindert Overfitting!\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),             # Numpy Array zu PIL Image (für transforms compatibility)\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Standardisiert alle Bilder auf 64x64\n",
    "    transforms.RandomHorizontalFlip(p=0.5),   # 50% Chance auf horizontalen Flip\n",
    "    transforms.RandomRotation(degrees=15),     # Zufällige Rotation bis 15° (Characters bleiben erkennbar)\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Farb-Variationen\n",
    "    transforms.ToTensor(),               # Konvertiert zu Tensor und normalisiert [0,1]\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalisiert zu [-1, 1]\n",
    "])\n",
    "\n",
    "# Test/Validation Transformations - Keine Augmentation für konsistente Evaluation\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),             # Numpy zu PIL\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Resize auf Standard-Größe\n",
    "    transforms.ToTensor(),               # Zu Tensor konvertieren\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Gleiche Normalisierung\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "OPTIMIERUNGSPOTENTIAL #2: DATA AUGMENTATION\n",
    "- Mixup/CutMix Augmentation hinzufügen\n",
    "- AutoAugment/RandAugment implementieren\n",
    "- Advanced Augmentation wie Elastic Transforms\n",
    "- Test Time Augmentation (TTA) für bessere Inferenz\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# CUSTOM DATASET CLASS\n",
    "# =============================================================================\n",
    "class SimpsonsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset Klasse für die Simpsons Charaktere\n",
    "    Erbt von torch.utils.data.Dataset für DataLoader Kompatibilität\n",
    "    \"\"\"\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images      # Numpy Array mit Bildern\n",
    "        self.labels = labels      # Numpy Array mit Labels (Integer-kodiert)\n",
    "        self.transform = transform # Optional: Transformation Pipeline\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)   # Anzahl Samples im Dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Gibt ein Sample (Image, Label) für gegebenen Index zurück\n",
    "        Wird vom DataLoader automatisch aufgerufen\n",
    "        \"\"\"\n",
    "        image = self.images[idx]  # Bild an Index idx\n",
    "        label = self.labels[idx]  # Entsprechendes Label\n",
    "        if self.transform:        # Falls Transformationen definiert sind\n",
    "            image = self.transform(image)  # Transformationen anwenden\n",
    "        return image, label       # Tuple zurückgeben\n",
    "\n",
    "\"\"\"\n",
    "OPTIMIERUNGSPOTENTIAL #3: DATASET CLASS\n",
    "- Memory Mapping für große Datasets\n",
    "- Lazy Loading implementieren (nur bei Bedarf laden)\n",
    "- Caching häufig verwendeter Samples\n",
    "- Multi-threaded Data Loading optimieren\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING & PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "# Alle Charakter-Ordner im Dataset Directory finden\n",
    "label_names = sorted([name for name in os.listdir(DATA_DIR)\n",
    "                     if os.path.isdir(os.path.join(DATA_DIR, name))])\n",
    "\n",
    "# Anzahl Bilder pro Charakter zählen (für Top-K Auswahl)\n",
    "image_counts = {label: len([f for f in os.listdir(os.path.join(DATA_DIR, label))\n",
    "                           if os.path.splitext(f)[1].lower() in VALID_EXTENSIONS])\n",
    "               for label in label_names}\n",
    "\n",
    "# Top 10 Charaktere mit den meisten Bildern auswählen (Class Balance)\n",
    "top_characters = [c for c, _ in Counter(image_counts).most_common(10)]\n",
    "\n",
    "# Label-Mapping erstellen: Charakter Name -> Integer Index\n",
    "label_map = {name: idx for idx, name in enumerate(top_characters)}\n",
    "\n",
    "# Listen für Images und Labels initialisieren\n",
    "images = []  # Wird alle Bilder enthalten\n",
    "labels = []  # Wird entsprechende Integer-Labels enthalten\n",
    "\n",
    "\"\"\"\n",
    "OPTIMIERUNGSPOTENTIAL #4: CLASS IMBALANCE\n",
    "- Weighted Loss Functions implementieren\n",
    "- SMOTE oder andere Oversampling Techniken\n",
    "- Focal Loss für schwierige Klassen\n",
    "- Stratified Sampling in DataLoader\n",
    "\"\"\"\n",
    "\n",
    "# Bilder laden und preprocessen\n",
    "for label in top_characters:                           # Für jeden der Top Charaktere\n",
    "    folder_path = os.path.join(DATA_DIR, label)        # Pfad zum Charakter-Ordner\n",
    "    img_count = 0                                      # Counter für Bilder pro Klasse\n",
    "\n",
    "    for img_name in os.listdir(folder_path):           # Für jedes Bild im Ordner\n",
    "        if img_count >= MAX_IMAGES_PER_CLASS:          # Max Images erreicht?\n",
    "            break                                      # Nächsten Charakter\n",
    "\n",
    "        # Prüfen ob Datei gültiges Bildformat hat\n",
    "        if os.path.splitext(img_name)[1].lower() not in VALID_EXTENSIONS:\n",
    "            print(f\"Warning: Skipping non-image file {os.path.join(folder_path, img_name)}\")\n",
    "            continue                                   # Nicht-Bild Dateien überspringen\n",
    "\n",
    "        img_path = os.path.join(folder_path, img_name) # Vollständiger Pfad zum Bild\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)   # Bild in Farbe laden\n",
    "\n",
    "        if img is None:                                # Laden fehlgeschlagen?\n",
    "            print(f\"Warning: Failed to load image {img_path}\")\n",
    "            continue                                   # Nächstes Bild\n",
    "\n",
    "        # OpenCV lädt in BGR, wir brauchen RGB für Konsistenz\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Grayscale Bilder zu RGB konvertieren (falls vorhanden)\n",
    "        if img.ndim == 2:                              # Nur 2 Dimensionen = Grayscale\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # Bild auf Standard-Größe resizen (wichtig für CNN Input!)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Bildformat validieren\n",
    "        if img.shape != (IMG_SIZE, IMG_SIZE, 3):       # Erwartete Shape: (64, 64, 3)\n",
    "            print(f\"Warning: Image {img_path} has invalid shape {img.shape}, expected ({IMG_SIZE}, {IMG_SIZE}, 3)\")\n",
    "            continue                                   # Ungültige Bilder überspringen\n",
    "\n",
    "        images.append(img)                             # Bild zur Liste hinzufügen\n",
    "        labels.append(label_map[label])                # Entsprechendes Integer-Label hinzufügen\n",
    "        img_count += 1                                 # Counter erhöhen\n",
    "\n",
    "# Listen zu NumPy Arrays konvertieren (effizienter für ML Operations)\n",
    "try:\n",
    "    images = np.array(images, dtype=np.uint8)          # uint8 für PIL Kompatibilität\n",
    "    labels = np.array(labels, dtype=np.int64)          # int64 für PyTorch CrossEntropyLoss\n",
    "except ValueError as e:\n",
    "    # Debugging Information falls Array-Konvertierung fehlschlägt\n",
    "    print(f\"Error converting to NumPy array: {e}\")\n",
    "    print(\"Shapes of first few images:\")\n",
    "    for i, img in enumerate(images[:5]):               # Erste 5 Bilder debuggen\n",
    "        print(f\"Image {i}: shape {np.array(img).shape if isinstance(img, np.ndarray) else 'Not an array'}\")\n",
    "    print(\"Total images collected:\", len(images))\n",
    "    raise                                              # Exception weiterwerfen\n",
    "\n",
    "# Label-Validierung (wichtig für korrekte Loss-Berechnung!)\n",
    "num_classes = len(top_characters)                      # Anzahl Klassen\n",
    "if labels.max() >= num_classes or labels.min() < 0:   # Labels außerhalb gültigem Bereich?\n",
    "    print(f\"Error: Labels contain invalid indices. Max label: {labels.max()}, Min label: {labels.min()}, Expected range: [0, {num_classes-1}]\")\n",
    "    raise ValueError(\"Invalid label indices detected\")\n",
    "\n",
    "# Arrays validieren\n",
    "print(f\"Images array shape: {images.shape}, Labels array shape: {labels.shape}\")\n",
    "\n",
    "\"\"\"\n",
    "OPTIMIERUNGSPOTENTIAL #5: DATA LOADING\n",
    "- Parallel Processing mit multiprocessing\n",
    "- Progressive Image Loading (kleinere Bilder zuerst)\n",
    "- Data Validation Pipeline implementieren\n",
    "- Corrupted Image Detection verbessern\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN/TEST SPLIT\n",
    "# =============================================================================\n",
    "\n",
    "# Stratified Split - gleiche Klassenverteilung in Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels,                                    # Input Data und Labels\n",
    "    test_size=0.2,                                    # 20% für Testing\n",
    "    stratify=labels,                                  # Gleiche Klassenverteilung\n",
    "    random_state=42                                   # Reproduzierbare Ergebnisse\n",
    ")\n",
    "\n",
    "# Dataset Objekte mit entsprechenden Transformationen erstellen\n",
    "train_dataset = SimpsonsDataset(X_train, y_train, transform=train_transforms)  # Mit Augmentation\n",
    "test_dataset = SimpsonsDataset(X_test, y_test, transform=test_transforms)      # Ohne Augmentation\n",
    "\n",
    "# DataLoader für effizientes Batch Loading erstellen\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)   # Training: gemischt\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)    # Test: nicht gemischt\n",
    "\n",
    "# Summary ausgeben\n",
    "print(f\"Loaded {len(images)} images across {len(top_characters)} characters\")\n",
    "print(f\"Training set: {len(X_train)} images, Test set: {len(X_test)} images\")\n",
    "\n",
    "# =============================================================================\n",
    "# CNN MODEL DEFINITION\n",
    "# =============================================================================\n",
    "\n",
    "class SimpsonsCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network für Simpsons Character Classification\n",
    "\n",
    "    Architektur:\n",
    "    - 3 Conv Layers mit steigender Kanalanzahl (Feature Hierarchie)\n",
    "    - MaxPooling nach jedem Conv Layer (Spatial Downsampling)\n",
    "    - 2 Fully Connected Layers (Classification Head)\n",
    "    - Dropout für Regularisierung\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpsonsCNN, self).__init__()\n",
    "\n",
    "        # Convolutional Layers - extrahieren Features\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)    # 3->32 channels, 3x3 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)                            # 2x2 MaxPooling (halbiert Größe)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 32->64 channels\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 64->128 channels\n",
    "\n",
    "        # Fully Connected Layers - für finale Klassifikation\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)                   # 128*8*8 nach 3x MaxPool von 64x64\n",
    "        self.dropout = nn.Dropout(0.5)                           # 50% Dropout gegen Overfitting\n",
    "        self.fc2 = nn.Linear(512, num_classes)                   # Output Layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward Pass durch das Netzwerk\n",
    "        Input: x mit Shape (batch_size, 3, 64, 64)\n",
    "        Output: Logits mit Shape (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        # Conv Block 1: Conv -> ReLU -> MaxPool (64x64 -> 32x32)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "        # Conv Block 2: Conv -> ReLU -> MaxPool (32x32 -> 16x16)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Conv Block 3: Conv -> ReLU -> MaxPool (16x16 -> 8x8)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        # Flatten für FC Layers: (batch, 128, 8, 8) -> (batch, 128*8*8)\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "\n",
    "        # FC Block 1: Linear -> ReLU -> Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Output Layer: Linear (keine Activation, da CrossEntropyLoss LogSoftmax eingebaut hat)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\"\"\"\n",
    "OPTIMIERUNGSPOTENTIAL #6: MODEL ARCHITECTURE\n",
    "- ResNet/DenseNet Connections für tiefere Netzwerke\n",
    "- Attention Mechanisms hinzufügen\n",
    "- EfficientNet als Backbone verwenden\n",
    "- Transfer Learning mit vortrainierten Models\n",
    "- Batch Normalization zwischen Layers\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# DEVICE SETUP & MODEL INITIALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "# Debugging Information für verfügbare Hardware\n",
    "print(f\"PyTorch version: {torch.__version__}\")              # PyTorch Version\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")       # CUDA verfügbar?\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")            # CUDA Version\n",
    "    try:\n",
    "        print(f\"GPU device: {torch.cuda.get_device_name(0)}\")  # GPU Name\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting GPU device name: {e}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")  # Apple Metal Performance Shaders\n",
    "\n",
    "# Device Selection mit robuster Fallback-Logik\n",
    "device = torch.device(\"cpu\")                                # Standard: CPU\n",
    "if torch.cuda.is_available():                               # CUDA verfügbar?\n",
    "    try:\n",
    "        torch.cuda.init()                                   # CUDA initialisieren\n",
    "        test_tensor = torch.ones(1, device=\"cuda\")          # Test-Tensor auf GPU\n",
    "        # device = torch.device(\"cuda\")\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # GPU verwenden\n",
    "        print(\"CUDA initialized successfully, using GPU.\")\n",
    "    except Exception as e:\n",
    "        print(f\"CUDA initialization failed: {e}. Falling back to CPU.\")\n",
    "else:\n",
    "    print(\"No GPU available or CUDA initialization failed, using CPU.\")\n",
    "\n",
    "# Model initialisieren und auf gewähltes Device verschieben\n",
    "try:\n",
    "    model = SimpsonsCNN(num_classes=len(top_characters)).to(device)  # Model auf Device\n",
    "    test_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE, device=device)  # Test Input\n",
    "    model(test_input)                                       # Forward Pass testen\n",
    "    print(f\"Model successfully moved to {device} and tested.\")\n",
    "except Exception as e:\n",
    "    # Fallback zu CPU falls GPU-Initialisierung fehlschlägt\n",
    "    print(f\"Error moving model to device {device}: {e}\")\n",
    "    print(\"Falling back to CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = SimpsonsCNN(num_classes=len(top_characters)).to(device)\n",
    "    test_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE, device=device)\n",
    "    model(test_input)\n",
    "    print(\"Model successfully moved to CPU and tested.\")\n",
    "\n",
    "# Loss Function und Optimizer initialisieren\n",
    "criterion = nn.CrossEntropyLoss()                          # Standard für Multi-Class Classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=INITIAL_LR)   # Adam Optimizer\n",
    "print(f\"Using {device} device for training\")\n",
    "\n",
    "\"\"\"\n",
    "OPTIMIERUNGSPOTENTIAL #7: TRAINING SETUP\n",
    "- Learning Rate Scheduler implementieren\n",
    "- Different Optimizers ausprobieren (AdamW, SGD mit Momentum)\n",
    "- Mixed Precision Training für GPU Speedup\n",
    "- Gradient Accumulation für größere effektive Batch Size\n",
    "- Model Checkpointing implementieren\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING LOOP\n",
    "# =============================================================================\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):                            # Für jede Epoche\n",
    "    model.train()                                          # Training Mode (Dropout aktiv)\n",
    "    running_loss = 0.0                                     # Loss Accumulator\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):  # Für jeden Batch\n",
    "        try:\n",
    "            # Tensors auf korrektes Device verschieben\n",
    "            inputs = inputs.to(device, non_blocking=True)   # Non-blocking für Speedup\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            # Device und Label Validierung (wichtig für Debugging!)\n",
    "            if inputs.device != device or labels.device != device:\n",
    "                raise RuntimeError(f\"Tensor device mismatch: inputs on {inputs.device}, labels on {labels.device}, expected {device}\")\n",
    "            if labels.max() >= num_classes or labels.min() < 0:\n",
    "                raise RuntimeError(f\"Invalid label values in batch: max {labels.max()}, min {labels.min()}, expected [0, {num_classes-1}]\")\n",
    "\n",
    "            # Standard Training Steps\n",
    "            optimizer.zero_grad()                          # Gradienten zurücksetzen\n",
    "            outputs = model(inputs)                        # Forward Pass\n",
    "            loss = criterion(outputs, labels)              # Loss berechnen\n",
    "\n",
    "            # Loss Validierung\n",
    "            if loss.device != device:\n",
    "                raise RuntimeError(f\"Loss on incorrect device: {loss.device}, expected {device}\")\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                raise RuntimeError(f\"Invalid loss value: {loss.item()}\")\n",
    "\n",
    "            # Gradient Clipping gegen exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            loss.backward()                                # Backward Pass (Gradienten berechnen)\n",
    "            optimizer.step()                               # Parameter updaten\n",
    "            running_loss += loss.item()                    # Loss akkumulieren\n",
    "\n",
    "        except Exception as e:\n",
    "            # Robuste Fehlerbehandlung mit CPU Fallback\n",
    "            print(f\"Error in batch {batch_idx+1}, epoch {epoch+1}: {e}\")\n",
    "            print(f\"Inputs device: {inputs.device}, Labels device: {labels.device}, Model device: {next(model.parameters()).device}\")\n",
    "            print(f\"Input shape: {inputs.shape}, Label shape: {labels.shape}, Label values: {labels.tolist()}\")\n",
    "            print(\"Falling back to CPU for this batch.\")\n",
    "\n",
    "            # Temporär zu CPU wechseln\n",
    "            model.to(\"cpu\")\n",
    "            inputs = inputs.to(\"cpu\")\n",
    "            labels = labels.to(\"cpu\")\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            model.to(device)  # Zurück zum ursprünglichen Device\n",
    "\n",
    "    # Epoch Summary\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {running_loss/len(train_loader):.4f}, Learning Rate: {INITIAL_LR:.6f}\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # EVALUATION ON TEST SET\n",
    "    # =============================================================================\n",
    "\n",
    "    model.eval()                                          # Evaluation Mode (Dropout deaktiviert)\n",
    "    correct = 0                                           # Korrekte Vorhersagen zählen\n",
    "    total = 0                                             # Gesamtanzahl Samples\n",
    "\n",
    "    with torch.no_grad():                                 # Keine Gradienten für Evaluation\n",
    "        for inputs, labels in test_loader:                # Für jeden Test Batch\n",
    "            inputs = inputs.to(device, non_blocking=True)  # Auf Device verschieben\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)                       # Forward Pass\n",
    "            _, predicted = torch.max(outputs.data, 1)     # Klasse mit höchster Wahrscheinlichkeit\n",
    "            total += labels.size(0)                       # Batch Size addieren\n",
    "            correct += (predicted == labels).sum().item() # Korrekte Vorhersagen zählen\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "\"\"\"\n",
    "OPTIMIERUNGSPOTENTIAL #8: TRAINING & EVALUATION\n",
    "- Validation Set für besseres Monitoring\n",
    "- Early Stopping implementieren\n",
    "- Learning Rate Scheduling\n",
    "- Confusion Matrix und Per-Class Metrics\n",
    "- Tensorboard/Wandb Logging\n",
    "- Model Ensemble für bessere Performance\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL SAVING\n",
    "# =============================================================================\n",
    "\n",
    "#torch.save(model.state_dict(), \"simpsons_cnn.pth\")        # Nur Model Weights speichern\n",
    "#print(\"Model saved as simpsons_cnn.pth\")\n",
    "\n",
    "\"\"\"\n",
    "FINALES OPTIMIERUNGSPOTENTIAL:\n",
    "1. Config Management: YAML/JSON configs\n",
    "2. Logging: Structured logging mit wandb/tensorboard\n",
    "3. Model Versioning: MLflow für Experiment Tracking\n",
    "4. Data Pipeline: mehr robuste Datenvalidierung\n",
    "5. Architecture: moderne Architekturen wie EfficientNet\n",
    "6. Training: Advanced Training Techniques (Mixed Precision, etc.)\n",
    "7. Deployment: Model Serving Pipeline\n",
    "8. Monitoring: Performance Monitoring in Production\n",
    "\"\"\""
   ],
   "id": "a0167191836ce64a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
